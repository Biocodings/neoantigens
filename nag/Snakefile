import glob
import os
from os.path import join, abspath, dirname, isfile, basename, splitext

from ngs_utils.vcf_utils import get_tumor_sample_name, vcf_contains_field
from ngs_utils.bcbio import BcbioProject
from ngs_utils.logger import critical, info, debug, warn, err
from ngs_utils.file_utils import verify_file
from reference_data import api as refdata

if config.get('genomes_dir'):
    refdata.find_genomes_dir(config.get('genomes_dir'))
print('Genomes dir:', refdata.genomes_dir)


SOMATIC_VCF     = config['somatic_vcf']
SNAME           = config.get('sample')
HLA_FILE        = config.get('hla_file')
RNA_BCBIO       = config.get('rna_bcbio')
RNA_SNAME       = config.get('rna_sample')
work_dir        = 'work'

GENOME                 = 'hg38'
ENSEMBL_GENOME         = 'GRCh38'
PIZZLY_ENSEMBL_RELEASE = config.get('ensembl_release', 95)
VEP_ENSEMBL_RELEASE    = config.get('ensembl_release', 98)
PYENSEMBL_DIR          = config.get('ensembl_dir', refdata.get_ref_file(genome=GENOME, key='pyensembl_data'))
VEP_DATA               = glob.glob(join(refdata.get_ref_file(genome=GENOME, key='pcgr_data'), '*/.vep'))[0]
IEDB_DIR               = config.get('iedb_dir', refdata.get_ref_file(key='iedb_dir'))
REF_FA                 = config.get('ref_fa', refdata.get_ref_file(genome=GENOME, key='fa'))
USE_REMOTE_DB          = config.get('internet_is_on', False)
PIZZLY_REF_FA          = config.get('pizzly_ref_fa')


################################################
### hg38 DNA Project. Required for HLA typing.

# dna_run = BcbioProject(DNA_BCBIO, include_samples=[DNA_SNAME])
# assert dna_run.genome_build == GENOME
# if len(dna_run.batch_by_name) == 0:
#     critical(f'Error: could not find a sample with the name {DNA_SNAME}. Check yaml file for available options: {dna_run.bcbio_yaml_fpath}')
# Batch objects index by tumor sample names
# batches = [b for b in dna_run.batch_by_name.values() if not b.is_germline() and b.tumor and b.normal]
# assert len(batches) == 1
# batch = batches[0]


# pVACtools parameters
EPITOPE_LENGTHS = '9'  #'8,9,10,11'
PREDICTORS_MHCI = [
    'NetMHCcons',  # NetMHCcons is ensemble of NetMHC,NetMHCpan,PickPocket
    'MHCflurry',
    'MHCnuggetsI',
    'SMM',
    'SMMPMBEC',
]
PREDICTORS_MHCII = [
    'NetMHCIIpan',
    'MHCnuggetsII',
    'NNalign',
    'SMMalign'
]

# pVACfuse parameters
PEP_5_PRIME_FLANK = 14  # Aminoacids to pick from both sides of the fusion junction peptide.
    # It should be long enough so your longest desigred epitope just covers the junction. Say,
    # if the longest epitope length is 11, use PEP_5_PRIME_FLANK of 10. Since MHC_II algorithms
    # always call epitopes of the length 15, we set PEP_5_PRIME_FLANK to 14.

# pVACseq parameters
MIN_NORMAL_COV = 5
MIN_TUMOR_COV = MIN_RNA_COV = 10
MAX_NORMAL_VAF = 2
MIN_TUMOR_VAF = MIN_RNA_VAF = config.get('min_tvaf', 10)
MIN_EXPN = 1  # TPM expression should be at least 1
EXCLUDE_NA = False


rule all:
    input:   expand('pvacseq_results/MHC_Class_{CLS}/' + SNAME + '.filtered.condensed.ranked.tsv', CLS=['I', 'II']),
             expand('pvacfuse_results/MHC_Class_{CLS}/' + SNAME + '.filtered.condensed.ranked.tsv', CLS=['I', 'II']),

rule pvacseq:
    input:   expand('pvacseq_results/MHC_Class_{CLS}/' + SNAME + '.filtered.condensed.ranked.tsv', CLS=['I', 'II']),

rule pvacfuse:
    input:   expand('pvacfuse_results/MHC_Class_{CLS}/' + SNAME + '.filtered.condensed.ranked.tsv', CLS=['I', 'II']),


def _pvac_cmdl(tool, input, sample, hla_types, output_dir, threads, other_params=''):
    cmd = (
        f'{tool} run '
        f'{input} '
        f'{sample} '
        f'"$(cat {hla_types})" '
        f'{" ".join(PREDICTORS_MHCI + PREDICTORS_MHCII)} '
        f'{output_dir} '
        f'-e {EPITOPE_LENGTHS} '
        f'--top-score-metric=lowest '
        # f'-t {threads} '
        f'--iedb-install-directory {IEDB_DIR} '
        f'--keep-tmp-files '
        f'{other_params} '
    )
    if USE_REMOTE_DB:
        cmd += \
            f' --net-chop-method cterm ' \
            f'--netmhc-stab'
    if EXCLUDE_NA:
        cmd += f' --exclude-NAs'
    return cmd

# rule pvacseq_filter:
#     input:  dynamic('pvacseq_results/MHC_Class_{cls}/{SNAME}.final.tsv'),
#     output: dynamic('pvacseq_results/MHC_Class_{cls}/{SNAME}.final.filt.tsv')
#     shell : 'pvacseq top_score_filter -m median MHC_Class_II/diploid_tumor.final.tsv MHC_Class_II/diploid_tumor.final.TOP.tsv'
    # also filer to remove epitopes shorter than FLANKING_PEPTIDE+1 that start earlier than FLANKING_PEPTIDE+1-len(epitope)
    # in output: len(epitope) = Peptide Length
    #            start        = Sub-peptide Position
    # explore why MHC II takes 31aa


################
### HLA types

# t_optitype = join(batch.tumor.dirpath, batch.tumor.name + '-hla-optitype.csv')

rule prep_hla:
    """ Create a file containing a single line of comma-separated HLA alleles
    """
    input:  HLA_FILE
    output: join(work_dir, 'hla_line.txt')
    shell: r"""
    grep -v ^sample {input} | tr ',' '\t' | cut -f3 | tr ';' '\n' | sort -u | tr '\n' ',' | head -c -1 > {output}
    """


################
### Small mutations (for pVACseq)

# t_vcf = verify_file(join(dna_run.date_dir, f'{batch.name}-ensemble-annotated.vcf.gz'))
t_vcf = SOMATIC_VCF

# rule vcf_set_af_dp:
#     input:   t_vcf
#     output:  join(work_dir, 'somatic.AFDP.vcf')
#     shell:  'pcgr_prep {input} | bcftools view -f.,PASS -Oz -o {output} && tabix -p vcf {output}'

rule vcf_af_filter:  # {batch}
    input:  SOMATIC_VCF
    output: join(work_dir, 'vcf_prep/somatic.AF_FILT.vcf.gz')
    params: tvaf = MIN_TUMOR_VAF / 100,
            nvaf = MAX_NORMAL_VAF / 100,
            tcov = MIN_TUMOR_COV,
            ncov = MIN_NORMAL_COV,
    shell:  """
    bcftools filter -i "\
    TUMOR_AF>={params.tvaf} && 
    NORMAL_AF<={params.nvaf} && 
    TUMOR_DP>={params.tcov} && \
    NORMAL_DP>={params.ncov}\
    " {input} -Oz -o {output} && tabix {output}
    """

rule drop_older_csq:
    input:
        vcf = join(work_dir, 'vcf_prep/somatic.AF_FILT.vcf.gz'),
    output:
        vcf = join(work_dir, 'vcf_prep/somatic.AF_FILT.CLEAN_PREV_VEP.vcf.gz'),
    run:
        cmd = f'cat {input.vcf}'
        # remove previous VEP annotation:
        filts_to_remove = [f'{f}' for f in ['INFO/CSQ'] if vcf_contains_field(input.vcf, f)]
        if filts_to_remove:
            cmd += f' | bcftools annotate -x "' + ','.join(f'{f}' for f in filts_to_remove) + '"'
        cmd += ' | bcftools view -f.,PASS -Oz -o {output.vcf} && tabix -p vcf {output.vcf}'
        shell(cmd)

# The --symbol option will include gene symbol in the annotation.
# The --terms SO option will result in Sequence Ontology terms being used for the consequences.
# The --tsl option adds transcript support level information to the annotation.
# The --hgvs option will result in HGVS identifiers being added to the annotation.
#   Requires the usage of the --fasta argument.
# The --cache option will result in the VEP cache being used for annotation.
# The --plugin Downstream option will run the Downstream plugin which will compute the
#   downstream protein sequence after a frameshift.
# The --plugin Wildtype option will run the Wildtype plugin which will include the transcript
#   protein sequence in the annotation.
rule vcf_vep:
    input:
        join(work_dir, 'vcf_prep/somatic.AF_FILT.CLEAN_PREV_VEP.vcf.gz'),
        vep_data = VEP_DATA,
        ref_fa = REF_FA,
    output:
        join(work_dir, 'vep/somatic.AF_FILT.VEP.vcf'),
    params:
        genome_build = ENSEMBL_GENOME,
        cache_version = VEP_ENSEMBL_RELEASE,
    shell:
        'vep '
        '--input_file {input} '
        '--format vcf '
        '--output_file {output} '
        '--vcf '
        '--force_overwrite '
        '--symbol '
        '--terms SO '
        '--tsl '
        '--hgvs '
        '--fasta {input.ref_fa} '
        '--pick '
        '--plugin Downstream '
        '--plugin Wildtype '
        '--dir_plugins {input.vep_data}/Plugins '
        '--assembly {params.genome_build} '
        '--offline '
        '--cache '
        '--dir_cache {input.vep_data} '
        '--cache_version {params.cache_version}'

rule vcf_select:
    input:
        join(work_dir, 'vep/somatic.AF_FILT.VEP.vcf')
    output:
        join(work_dir, 'vep/somatic.AF_FILT.VEP.TUMOR_SAMPLE.vcf')
    params:
        sample = lambda wc, input: get_tumor_sample_name(input[0])
    shell:
        'bcftools view -s {params.sample} {input} | grep -v PEDIGREE > {output}'


#################
### Adding RNA information

rna_run = BcbioProject(RNA_BCBIO, include_samples=[RNA_SNAME])
assert rna_run.genome_build == 'hg38'
rna_sample = rna_run.samples[0]
rna_bam = rna_sample.bam
rna_counts_tx = join(rna_sample.dirpath, 'kallisto', 'abundance.tsv')
rna_counts_gx = join(rna_run.date_dir, 'annotated_combined.counts')
rna_pizzly_prefix = join(rna_sample.dirpath, 'pizzly', RNA_SNAME)
fastq = [f for f in rna_sample.sample_info['files'] if not f.endswith('.bam') and verify_file(f, silent=True)]
if not fastq:
    bam = rna_sample.sample_info['files'][0]
    assert bam.endswith('bam'), f'Input for sample {RNA_SNAME} is neither a pair of fastq nor a BAM file: {bam}'
    bam_name = splitext(basename(bam))[0]
    fastq1 = verify_file(join(rna_run.work_dir, 'align_prep', f'{bam_name}-1.fq.gz'))
    fastq2 = verify_file(join(rna_run.work_dir, 'align_prep', f'{bam_name}-2.fq.gz'))
    if not fastq1 and not fastq2:
        critical('Could not find RNAseq input fastq for requantification')
    fastq = [fastq1, fastq2]

################
### Variant coverage and expression (for pVACseq coverageFilter)

rule extract_snps_sites:  # 1-based coordinates
    input:
        join(work_dir, 'vep/somatic.AF_FILT.VEP.TUMOR_SAMPLE.vcf')
    output:
        join(work_dir, 'somatic_snp_sites.txt'),
    shell:
        'bcftools view -v snps {input} | '
        'bcftools query -f "%CHROM \\t %POS \\n" | '
        'awk \'{{ OFS="\\t" }} {{ print $1,$2,$2 }}\' > {output}'

rule extract_indels_sites:
    input:
        join(work_dir, 'vep/somatic.AF_FILT.VEP.TUMOR_SAMPLE.vcf')
    output:
        join(work_dir, 'somatic_indel_sites.txt'),
    shell:
        'bcftools view -v indels {input} | '
        'bcftools query -f "%CHROM \\t %POS \\n" | '
        'awk \'{{ OFS="\\t" }}{{ print $1,$2,$2 }}\' > {output}'

rule rna_bam_readcount_snps:
    input:
        bam = rna_bam,
        sites = join(work_dir, 'somatic_{type}_sites.txt'),
        ref_fa = REF_FA,
    params:
        indel_opt = lambda wildcards: '-i ' if wildcards.type == 'indel' else ''
    output:
        join(work_dir, 'trna_{type}_coverage_file.txt'),
    shell:
        'bam-readcount -f {input.ref_fa} --max-warnings 1 '
        '-l {input.sites} {input.bam} {params.indel_opt} > {output}'

# rule merge_rna_bam_readcount:
#     input:
#         expand(join(work_dir, 'trna_{type}_coverage_file.txt'), type=['indel', 'snp'])
#     output:
#         join(work_dir, 'trna_coverage_file.txt')
#     shell:
#         'cat {input} > {output}'

rule rna_coverage_anno_snp:
    input:
        vcf = join(work_dir, 'vep/somatic.AF_FILT.VEP.TUMOR_SAMPLE.vcf'),
        cov_file = join(work_dir, 'trna_snp_coverage_file.txt'),
    output:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.vcf')
    shell:
        'vcf-readcount-annotator {input.vcf} {input.cov_file} '
        'RNA -t snv -o {output.vcf}'

rule rna_coverage_anno_indel:
    input:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.vcf'),
        cov_file = join(work_dir, 'trna_indel_coverage_file.txt'),
    output:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.RNAAFINDEL.vcf')
    shell:
        'vcf-readcount-annotator {input.vcf} {input.cov_file} '
        'RNA -t indel -o {output.vcf}'


rule transcript_expression_anno:
    input:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.RNAAFINDEL.vcf'),
        expr_file = rna_counts_tx,
    output:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.RNAAFINDEL.TX.vcf'),
    shell:
        'vcf-expression-annotator {input.vcf} {input.expr_file} '
        'kallisto transcript -o {output.vcf}'


rule gene_expression_anno:
    input:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.RNAAFINDEL.TX.vcf'),
        expr_file = rna_counts_gx,
    output:
        vcf = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.RNAAFINDEL.TX.GX.vcf'),
    params:
        sname = RNA_SNAME
    shell:
        'vcf-expression-annotator {input.vcf} {input.expr_file} '
        'custom gene --id-column id --expression-column {params.sname} -o {output.vcf}'

#################
### prepare fusions (for pVACfuse)

rule rna_pizzly_to_bedpe:
    input:  rna_pizzly_prefix + '-flat-filtered.tsv',
            rna_pizzly_prefix + '.json',
            rna_pizzly_prefix + '.fusions.fasta',
            reads1 = fastq[0],
            reads2 = fastq[1],
    params: prefix = rna_pizzly_prefix,
            pep_5_prime_flank = PEP_5_PRIME_FLANK,
            pyensembl_basedir = dirname(PYENSEMBL_DIR),
            pyensembl_release = PIZZLY_ENSEMBL_RELEASE,
            pizzly_ref_fa_opt = f'--pizzly-ref-fa {PIZZLY_REF_FA} ' if PIZZLY_REF_FA else '',
    output: bedpe = join(work_dir, 'pizzly', SNAME + '.bedpe')
    shell:
        'export PYENSEMBL_CACHE_DIR={params.pyensembl_basedir} && '
        'pizzly_to_bedpe.py {params.prefix} -o {output.bedpe} -e {params.pyensembl_release} '
        '-p {params.pep_5_prime_flank} -r {input.reads1} -r {input.reads2} '
        '{params.pizzly_ref_fa_opt}'

rule run_pvacseq:
    input:
        vcf       = join(work_dir, 'afdp/somatic.AF_FILT.VEP.TUMOR_SAMPLE.RNAAFSNP.RNAAFINDEL.TX.GX.vcf'),
        hla_types = join(work_dir, 'hla_line.txt'),
    output:
        expand('pvacseq_results/MHC_Class_{CLS}/' + SNAME + '.filtered.condensed.ranked.tsv', CLS=['I', 'II']),
    params:
        out_dir = 'pvacseq_results'
    threads: 10
    run:
        with open(input.vcf) as fh:
            lines_num = [l for l in fh.readlines() if not l.startswith('#')]
        if len(lines_num) == 0:
            warn('No mutations to run pVACseq.')
            shell('touch {output}')
        else:
            shell(_pvac_cmdl(
                'pvacseq',
                '{input.vcf}',
                SNAME,
                '{input.hla_types}',
                '{params.out_dir}',
                threads,
                f'--trna-cov {MIN_RNA_COV} '
                f'--trna-vaf {MIN_RNA_VAF} '
                f'--expn-val {MIN_EXPN} '
            ))
            for of in output:
                if not isfile(of):
                    shell(f'touch {of}')

rule run_pvacfuse:
    input:
        bedpe     = join(work_dir, 'pizzly', SNAME + '.bedpe'),
        hla_types = join(work_dir, 'hla_line.txt'),
    output:
        expand('pvacfuse_results/MHC_Class_{CLS}/' + SNAME + '.filtered.condensed.ranked.tsv', CLS=['I', 'II']),
    params:
        out_dir = 'pvacfuse_results'
    threads: 10
    run:
        with open(input.bedpe) as fh:
            lines_num = [l for l in fh.readlines() if not l.startswith('chr')]
        if len(lines_num) == 0:
            warn('No fusions to run pVACfuse.')
            shell('touch {output}')
        else:
            bedpe = join(params.out_dir, SNAME + '.bedpe')
            shell(f'grep -v ^chr {input.bedpe} > {bedpe}')
            shell(_pvac_cmdl(
                'pvacfuse',
                bedpe,
                SNAME,
                '{input.hla_types}',
                '{params.out_dir}',
                threads,
            ))
            for of in output:
                if not isfile(of):
                    shell(f'touch {of}')

    rule pvacseq_extra_input:
        input:  transcript_expn_file        = join(work_dir, 'transcript_expn_file') if RNA_SNAME else [],
                trna_snvs_coverage_file     = join(work_dir, 'trna_snvs_coverage_file') if RNA_SNAME else [],
                trna_indels_coverage_file   = join(work_dir, 'trna_indels_coverage_file')if RNA_SNAME else [],
        output:                               join(work_dir, 'pvacseq_extra_input_file_list.yaml')
        run:
            with open(output[0], 'w') as out_fh:
                for fpath in input:
                    name = basename(fpath)
                    out_fh.write(f'{name}: {abspath(fpath)}\n')


