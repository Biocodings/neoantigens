import os

shell.executable(os.environ.get('SHELL', 'bash'))
shell.prefix("")

from os.path import join, abspath, dirname, isfile, basename, splitext
from ngs_utils.bcbio import BcbioProject
from ngs_utils.logger import critical, info, debug, warn, err
from ngs_utils.file_utils import verify_file
from hpc_utils.hpc import find_loc, get_ref_file


DNA_BCBIO     = config['dna_bcbio']
DNA_SNAME     = config.get('dna_sample')
RNA_BCBIO     = config.get('rna_bcbio')
RNA_SNAME     = config.get('rna_sample')
SNAME         = config.get('sample') or DNA_SNAME
work_dir      = 'work'


loc = find_loc()
ENSEMBL_DIR   = config.get('ensembl_dir', loc.ensembl_dir)
ENSEMBL_VERS  = config.get('ensembl_release', 91)
VEP_DATA      = config.get('vep_data', loc.vep_data)
IEDB_DIR      = config.get('iedb_dir', loc.iedb_dir)
REF_FA        = config.get('ref_fa', get_ref_file('hg38', loc=loc))
USE_REMOTE_DB = config.get('internet_is_on', False)


################################################
### hg38 DNA Project. Required for HLA typing.

dna_run = BcbioProject(DNA_BCBIO, include_samples=[DNA_SNAME])
assert dna_run.genome_build == 'hg38'
if len(dna_run.batch_by_name) == 0:
    critical(f'Error: could not find a sample with the name {DNA_SNAME}. Check yaml file for available options: {dna_run.bcbio_yaml_fpath}')
# Batch objects index by tumor sample names
batches = [b for b in dna_run.batch_by_name.values() if not b.is_germline() and b.tumor and b.normal]
assert len(batches) == 1
batch = batches[0]


# pVACtools parameters
EPITOPE_LENGTHS = '8,9,10,11'
PREDICTORS = 'NetMHCcons NetMHCIIpan NNalign SMM SMMPMBEC SMMalign'  # NetMHCcons is ensemble of NetMHC,NetMHCpan,PickPocket

# pVACfuse parameters
PEP_5_PRIME_FLANK = 14  # Aminoacids to pick from both sides of the fusion junction peptide.
    # It should be long enough so your longest desigred epitope just covers the junction. Say,
    # if the longest epitope length is 11, use PEP_5_PRIME_FLANK of 10. Since MHC_II algorithms
    # always call epitopes of the length 15, we set PEP_5_PRIME_FLANK to 14.

# pVACseq parameters
MIN_NORMAL_COV = 5
MIN_TUMOR_COV = MIN_RNA_COV = 10
MAX_NORMAL_VAF = 2
MIN_TUMOR_VAF = MIN_RNA_VAF = config.get('min_tvaf', 10)
MIN_EXPN = 1  # TPM expression should be at least 1
EXCLUDE_NA = False


rule all:
    input:   dynamic('pvacseq_results/MHC_Class_{cls}/'  + SNAME + '.final.tsv'),
             dynamic('pvacfuse_results/MHC_Class_{cls}/' + SNAME + '.final.tsv')

rule pvacseq:
    input:   dynamic('pvacseq_results/MHC_Class_{cls}/'  + SNAME + '.final.tsv')

rule pvacfuse:
    input:   dynamic('pvacfuse_results/MHC_Class_{cls}/' + SNAME + '.final.tsv')


def _pvac_cmdl(tool, input, sample, hla_types, output_dir, other_params=''):
    cmd = (f'{tool} run {input} {sample} "$(cat {hla_types})" {PREDICTORS} {output_dir} '
           f'-e {EPITOPE_LENGTHS} --top-score-metric=lowest -t '
           f'--iedb-install-directory {IEDB_DIR} --keep-tmp-files {other_params} ')
    if USE_REMOTE_DB:
        cmd += f' --net-chop-method cterm --netmhc-stab'
    if EXCLUDE_NA:
        cmd += f' --exclude-NAs'
    return cmd

# rule pvacseq_filter:
#     input:  dynamic('pvacseq_results/MHC_Class_{cls}/{SNAME}.final.tsv'),
#     output: dynamic('pvacseq_results/MHC_Class_{cls}/{SNAME}.final.filt.tsv')
#     shell : 'pvacseq top_score_filter -m median MHC_Class_II/diploid_tumor.final.tsv MHC_Class_II/diploid_tumor.final.TOP.tsv'
    # also filer to remove epitopes shorter than FLANKING_PEPTIDE+1 that start earlier than FLANKING_PEPTIDE+1-len(epitope)
    # in output: len(epitope) = Peptide Length
    #            start        = Sub-peptide Position
    # explore why MHC II takes 31aa

rule run_pvacseq:
    input:  vcf         = join(work_dir, 'somatic.PON.VEP.SELECT.vcf'),
            hla_types   = join(work_dir, 'hla_line.txt'),
            extra_input = join(work_dir, 'pvacseq_extra_input_file_list.yaml')
    output: dynamic('pvacseq_results/MHC_Class_{cls}/{SNAME}.final.tsv')
    params: out_dir = 'pvacseq_results'
    shell:  _pvac_cmdl('pvacseq', '{input.vcf}', SNAME, '{input.hla_types}', '{params.out_dir}',\
                       f'--normal-cov {MIN_RNA_VAF} '\
                       f'--tdna-cov {MIN_TUMOR_COV} '\
                       f'--trna-cov {MIN_RNA_COV} '\
                       f'--normal-vaf {MAX_NORMAL_VAF} '\
                       f'--tdna-vaf {MIN_TUMOR_VAF} '\
                       f'--trna-vaf {MIN_RNA_VAF} '\
                       f'--expn-val {MIN_EXPN} '\
                       '-i {input.extra_input}')

rule run_pvacfuse:
    input:  bedpe       =  join(work_dir, 'pizzly', SNAME + '.bedpe'),
            hla_types   = join(work_dir, 'hla_line.txt')
    output: dynamic('pvacfuse_results/MHC_Class_{cls}/{SNAME}.final.tsv')
    params: out_dir = 'pvacfuse_results'
    shell:  _pvac_cmdl('pvacfuse', '<(grep -v ^chr {input.bedpe})', SNAME, '{input.hla_types}', '{params.out_dir}')


################
### HLA types

t_optitype = join(batch.tumor.dirpath, batch.tumor.name + '-hla-optitype.csv')

rule prep_hla:
    """ Create a file containing a single line of comma-separated HLA alleles
    """
    input:  t_optitype
    output: join(work_dir, 'hla_line.txt')
    shell: "grep -v ^sample {input} | tr ',' '\t' | cut -f3 | tr ';' '\n' | sort -u | tr '\n' ',' | head -c -1"
           " > {output}"


################
### Small mutations (for pVACseq)

t_vcf = verify_file(join(dna_run.date_dir, f'{batch.name}-ensemble-annotated.vcf.gz'))

rule vcf_pon:
    input:  t_vcf
    output: join(work_dir, 'somatic.PON.vcf')
    params: genome = 'hg38'
    shell:  'pon_anno -g {params.genome} {input} -h1 | bcftools view -f.,PASS -o {output}'

rule vcf_vep:
    input:  join(work_dir, 'somatic.PON.vcf'),
            vep_data = VEP_DATA,
    output: join(work_dir, 'somatic.PON.VEP.vcf')
    params: assembly = 'GRCh38'
    shell:  '''
    vep --input_file {input} --format vcf --output_file {output} --vcf --force_overwrite \
    --pick --symbol --terms SO --plugin Downstream --plugin Wildtype \
    --cache --dir_cache {input.vep_data}/GRCh38 --dir_plugins {input.vep_data}/Plugins \
    --assembly {params.assembly} --offline
    '''

rule vcf_select:
    input:  join(work_dir, 'somatic.PON.VEP.vcf')
    output: join(work_dir, 'somatic.PON.VEP.SELECT.vcf')
    params: sample = DNA_SNAME
    shell:  'bcftools view -s {params.sample} {input} > {output}'

################
### Variant coverage and expression (for pVACseq)

rule extract_snps:
    input:  join(work_dir, 'somatic.PON.VEP.SELECT.vcf')
    output: join(work_dir, 'somatic_snps_sites.txt'),
    shell:  """
bcftools view -v snps {input} | 
bcftools query -f "%CHROM \\t %POS \\n" | 
awk '{{ OFS="\\t" }} {{ print $1,$2-1,$2 }}' > {output}
"""

rule extract_indels:
    input:  join(work_dir, 'somatic.PON.VEP.SELECT.vcf')
    output: join(work_dir, 'somatic_indels_sites.txt'),
    shell:  """
bcftools view -v indels {input} | 
bcftools query -f "%CHROM \\t %POS \\t %LEN \\n" | 
awk '{{ OFS="\\t" }}{{ print $1,$2-1,$2+$3-1 }}' > {output}
"""

# WGS BAMs (for pVACseq coverageFilter)

t_bam = verify_file(batch.tumor.bam, silent=True)
if t_bam:
    # Also check variant AF frequency to match tumor purity?
    rule tumor_dna_coverage_snps:
        input:  bam = t_bam,
                sites = join(work_dir, 'somatic_snps_sites.txt'),
                ref_fa = REF_FA,
        output: join(work_dir, 'tdna_snvs_coverage_file'),
        shell: 'bam-readcount -f {input.ref_fa} -w 1 -l {input.sites} {input.bam} > {output}'

    rule tumor_dna_coverage_indels:
        input:  bam = t_bam,
                sites = join(work_dir, 'somatic_indels_sites.txt'),
                ref_fa = REF_FA,
        output: join(work_dir, 'tdna_indels_coverage_file'),
        shell: 'bam-readcount -f {input.ref_fa} -w 1 -l {input.sites} {input.bam} -i > {output}'

n_bam = verify_file(batch.normal.bam, silent=True)
if n_bam:
    # Also check variant AF frequency to match tumor purity?
    rule normal_dna_coverage_snps:
        input:  bam = n_bam,
                sites = join(work_dir, 'somatic_snps_sites.txt'),
                ref_fa = REF_FA,
        output: join(work_dir, 'normal_snvs_coverage_file'),
        shell: 'bam-readcount -f {input.ref_fa} -w 1 -l {input.sites} {input.bam} > {output}'

    rule normal_dna_coverage_indels:
        input:  bam = n_bam,
                sites = join(work_dir, 'somatic_indels_sites.txt'),
                ref_fa = REF_FA,
        output: join(work_dir, 'normal_indels_coverage_file'),
        shell: 'bam-readcount -f {input.ref_fa} -w 1 -l {input.sites} {input.bam} -i > {output}'

if RNA_SNAME:
    rna_run = BcbioProject(RNA_BCBIO, include_samples=[RNA_SNAME])
    rna_sample = rna_run.samples[0]
    rna_bam = rna_sample.bam
    rna_counts = join(rna_sample.dirpath, 'kallisto', 'abundance.tsv')
    rna_pizzly_prefix = join(rna_sample.dirpath, 'pizzly', RNA_SNAME)
    fastq = [f for f in rna_sample.sample_info['files'] if not f.endswith('.bam') and verify_file(f, silent=True)]

    # RNAseq BAMs (for pVACseq coverageFilter)

    rule rna_coverage_snps:
        input:  bam = rna_bam,
                sites = join(work_dir, 'somatic_snps_sites.txt'),
                ref_fa = REF_FA,
        output: join(work_dir, 'trna_snvs_coverage_file'),
        shell: 'bam-readcount -f {input.ref_fa} -w 1 -l {input.sites} {input.bam} > {output}'

    rule rna_coverage_indels:
        input:  bam = rna_bam,
                sites = join(work_dir, 'somatic_indels_sites.txt'),
                ref_fa = REF_FA,
        output: join(work_dir, 'trna_indels_coverage_file'),
        shell: 'bam-readcount -f {input.ref_fa} -w 1 -l {input.sites} {input.bam} -i > {output}'

    # Transcript expression (for pVACseq coverageFilter)

    rule rna_expression:
        input:  rna_counts,
        output: join(work_dir, 'transcript_expn_file'),
        shell: 'cut -f1,5 {input} | sed "s/target_id/tracking_id/" | sed "s/tpm/FPKM/" > {output}'

    #################
    ### prepare fusions (for pVACfuse)

    rule rna_pizzly_to_bedpe:
        input:  rna_pizzly_prefix + '-flat-filtered.tsv',
                rna_pizzly_prefix + '.json',
                rna_pizzly_prefix + '.fusions.fasta',
                reads1 = fastq[0] if len(fastq) > 0 else [],
                reads2 = fastq[1] if len(fastq) > 1 else [],
        params: prefix = rna_pizzly_prefix,
                pep_5_prime_flank = PEP_5_PRIME_FLANK,
        output: join(work_dir, 'pizzly', SNAME + '.bedpe')
        shell:  'export PYENSEMBL_CACHE_DIR={ENSEMBL_DIR} && pizzly_to_bedpe.py {params.prefix} -o {output} ' \
                '-p {params.pep_5_prime_flank} -r {input.reads1} -r {input.reads2} --no-filtering ' \
                '&& [ -s {output} ]'


################
### Extra inputs files (for pVACsesq coverageFilter)

rule pvacseq_extra_input:
    input:  transcript_expn_file        = join(work_dir, 'transcript_expn_file')if RNA_SNAME else [],
            trna_snvs_coverage_file     = join(work_dir, 'trna_snvs_coverage_file') if RNA_SNAME else [],
            trna_indels_coverage_file   = join(work_dir, 'trna_indels_coverage_file')if RNA_SNAME else [],
            tdna_snvs_coverage_file     = join(work_dir, 'tdna_snvs_coverage_file') if t_bam else [],
            tdna_indels_coverage_file   = join(work_dir, 'tdna_indels_coverage_file') if t_bam else [],
            normal_snvs_coverage_file   = join(work_dir, 'normal_snvs_coverage_file') if n_bam else [],
            normal_indels_coverage_file = join(work_dir, 'normal_indels_coverage_file') if n_bam else [],
    output:                               join(work_dir, 'pvacseq_extra_input_file_list.yaml')
    run:
        with open(output[0], 'w') as out_fh:
            for fpath in input:
                name = basename(fpath)
                out_fh.write(f'{name}: {abspath(fpath)}\n')


